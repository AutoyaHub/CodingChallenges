{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coding Challenge: Text Query Engine**\n",
    "\n",
    "The objective of this challenge is to build a Text Query Engine in Python.\n",
    "\n",
    "Your application will receive a series of text documents as a list of strings:\n",
    "\n",
    "```\n",
    "documents = [\n",
    "    \"The quick brown fox jumped over the lazy dog\",\n",
    "    \"A rose by any other name would smell as sweet\",\n",
    "    \"To be or not to be, that is the question\",\n",
    "    \"In the end, it's not the years in your life that count. It's the life in your years\",\n",
    "    \"You miss 100% of the shots you don't take\",\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "And a list of queries:\n",
    "\n",
    "```\n",
    "queries = [\"quick brown\", \"rose name\", \"life years\", \"you miss\"]\n",
    "\n",
    "```\n",
    "\n",
    "The engine should:\n",
    "\n",
    "1. Take the list of documents and build an internal representation of the text.\n",
    "2. Take a list of query words.\n",
    "3. Return a list of lists. Each list corresponds to a query and contains the document IDs that match the query, sorted by their relevance to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: quick brown\n",
      "  1. The quick brown fox jumped over the lazy dog\n",
      "  2. You miss 100% of the shots you don't take\n",
      "  3. In the end, it's not the years in your life that count. It's the life in your years\n",
      "  4. To be or not to be, that is the question\n",
      "  5. A rose by any other name would smell as sweet\n",
      "\n",
      "Query: rose name\n",
      "  1. A rose by any other name would smell as sweet\n",
      "  2. You miss 100% of the shots you don't take\n",
      "  3. In the end, it's not the years in your life that count. It's the life in your years\n",
      "  4. To be or not to be, that is the question\n",
      "  5. The quick brown fox jumped over the lazy dog\n",
      "\n",
      "Query: life years\n",
      "  1. In the end, it's not the years in your life that count. It's the life in your years\n",
      "  2. You miss 100% of the shots you don't take\n",
      "  3. To be or not to be, that is the question\n",
      "  4. A rose by any other name would smell as sweet\n",
      "  5. The quick brown fox jumped over the lazy dog\n",
      "\n",
      "Query: you miss\n",
      "  1. You miss 100% of the shots you don't take\n",
      "  2. In the end, it's not the years in your life that count. It's the life in your years\n",
      "  3. To be or not to be, that is the question\n",
      "  4. A rose by any other name would smell as sweet\n",
      "  5. The quick brown fox jumped over the lazy dog\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "class TextQueryEngine:\n",
    "    \"\"\"Basic Solution\"\"\"\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = TfidfVectorizer(lowercase=True, stop_words='english')\n",
    "        self.document_vectors = self.vectorizer.fit_transform(documents)\n",
    "\n",
    "    def search(self, queries):\n",
    "        query_vectors = self.vectorizer.transform(queries)\n",
    "        similarity_scores = cosine_similarity(query_vectors, self.document_vectors)\n",
    "\n",
    "        results = []\n",
    "        for scores in similarity_scores:\n",
    "            ranked_indices = np.argsort(scores)[::-1]\n",
    "            results.append([self.documents[i] for i in ranked_indices])\n",
    "\n",
    "        return results\n",
    "\n",
    "# Instantiate the engine with a list of documents\n",
    "documents = [\n",
    "    \"The quick brown fox jumped over the lazy dog\",\n",
    "    \"A rose by any other name would smell as sweet\",\n",
    "    \"To be or not to be, that is the question\",\n",
    "    \"In the end, it's not the years in your life that count. It's the life in your years\",\n",
    "    \"You miss 100% of the shots you don't take\",\n",
    "]\n",
    "engine = TextQueryEngine(documents)\n",
    "\n",
    "# Query the engine with a list of queries\n",
    "queries = [\"quick brown\", \"rose name\", \"life years\", \"you miss\"]\n",
    "results = engine.search(queries)\n",
    "\n",
    "for query, result in zip(queries, results):\n",
    "    print(f\"Query: {query}\")\n",
    "    for rank, document in enumerate(result, 1):\n",
    "        print(f\"  {rank}. {document}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: quick brown\n",
      "  1. The quick brown fox jumped over the lazy dog\n",
      "\n",
      "Query: rose name\n",
      "  1. A rose by any other name would smell as sweet\n",
      "\n",
      "Query: life years\n",
      "  1. In the end, it's not the years in your life that count. It's the life in your years\n",
      "\n",
      "Query: you miss\n",
      "  1. You miss 100% of the shots you don't take\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class TextQueryEngine:\n",
    "    \"\"\"Advanced solution\"\"\"\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = CountVectorizer(lowercase=True, stop_words='english')\n",
    "        self.document_term_matrix = self.vectorizer.fit_transform(documents).toarray()\n",
    "        self.index = self.build_index()\n",
    "\n",
    "    def build_index(self):\n",
    "        index = defaultdict(list)\n",
    "        for word, idx in self.vectorizer.vocabulary_.items():\n",
    "            for doc_id, count in enumerate(self.document_term_matrix[:, idx]):\n",
    "                if count > 0:\n",
    "                    index[word].append(doc_id)\n",
    "        return index\n",
    "\n",
    "    def search(self, queries):\n",
    "        results = []\n",
    "        for query in queries:\n",
    "            query_vector = self.vectorizer.transform([query]).toarray()[0]\n",
    "            scores = defaultdict(int)\n",
    "            for word, idx in self.vectorizer.vocabulary_.items():\n",
    "                if query_vector[idx] > 0:\n",
    "                    for doc_id in self.index[word]:\n",
    "                        scores[doc_id] += self.document_term_matrix[doc_id, idx]\n",
    "            ranked_indices = [doc_id for doc_id, _ in sorted(scores.items(), key=lambda x: x[1], reverse=True)]\n",
    "            results.append([self.documents[i] for i in ranked_indices])\n",
    "        return results\n",
    "\n",
    "# Instantiate the engine with a list of documents\n",
    "documents = [\n",
    "    \"The quick brown fox jumped over the lazy dog\",\n",
    "    \"A rose by any other name would smell as sweet\",\n",
    "    \"To be or not to be, that is the question\",\n",
    "    \"In the end, it's not the years in your life that count. It's the life in your years\",\n",
    "    \"You miss 100% of the shots you don't take\",\n",
    "]\n",
    "engine = TextQueryEngine(documents)\n",
    "\n",
    "# Query the engine with a list of queries\n",
    "queries = [\"quick brown\", \"rose name\", \"life years\", \"you miss\"]\n",
    "results = engine.search(queries)\n",
    "\n",
    "for query, result in zip(queries, results):\n",
    "    print(f\"Query: {query}\")\n",
    "    for rank, document in enumerate(result, 1):\n",
    "        print(f\"  {rank}. {document}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: quick brown\n",
      "Matching documents:\n",
      "Document ID: 0, Document: The quick brown fox jumped over the lazy dog\n",
      "\n",
      "Query: rose name\n",
      "Matching documents:\n",
      "Document ID: 1, Document: A rose by any other name would smell as sweet\n",
      "\n",
      "Query: life years\n",
      "Matching documents:\n",
      "Document ID: 3, Document: In the end, it's not the years in your life that count. It's the life in your years\n",
      "Document ID: 3, Document: In the end, it's not the years in your life that count. It's the life in your years\n",
      "\n",
      "Query: you miss\n",
      "Matching documents:\n",
      "Document ID: 4, Document: You miss 100% of the shots you don't take\n",
      "Document ID: 4, Document: You miss 100% of the shots you don't take\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class TextQueryEngine:\n",
    "    \"\"\"Bad Chat GPT Solution\"\"\"\n",
    "    def __init__(self, documents):\n",
    "        self.inverted_index = {}\n",
    "        self.build_index(documents)\n",
    "\n",
    "    def build_index(self, documents):\n",
    "        for doc_id, document in enumerate(documents):\n",
    "            words = document.lower().split()\n",
    "            for word in words:\n",
    "                if word not in self.inverted_index:\n",
    "                    self.inverted_index[word] = []\n",
    "                self.inverted_index[word].append(doc_id)\n",
    "\n",
    "    def search(self, queries):\n",
    "        results = []\n",
    "        for query in queries:\n",
    "            query_words = query.lower().split()\n",
    "            query_results = []\n",
    "            if query_words:\n",
    "                query_results = self.inverted_index.get(query_words[0], [])\n",
    "\n",
    "                for word in query_words[1:]:\n",
    "                    query_results = [\n",
    "                        doc_id\n",
    "                        for doc_id in query_results\n",
    "                        if doc_id in self.inverted_index.get(word, [])\n",
    "                    ]\n",
    "\n",
    "            query_results = sorted(query_results, key=lambda x: documents[x])\n",
    "            results.append(query_results)\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "documents = [\n",
    "    \"The quick brown fox jumped over the lazy dog\",\n",
    "    \"A rose by any other name would smell as sweet\",\n",
    "    \"To be or not to be, that is the question\",\n",
    "    \"In the end, it's not the years in your life that count. It's the life in your years\",\n",
    "    \"You miss 100% of the shots you don't take\",\n",
    "]\n",
    "\n",
    "queries = [\"quick brown\", \"rose name\", \"life years\", \"you miss\"]\n",
    "\n",
    "query_engine = TextQueryEngine(documents)\n",
    "search_results = query_engine.search(queries)\n",
    "\n",
    "for query, results in zip(queries, search_results):\n",
    "    print(f\"Query: {query}\")\n",
    "    if results:\n",
    "        print(\"Matching documents:\")\n",
    "        for doc_id in results:\n",
    "            print(f\"Document ID: {doc_id}, Document: {documents[doc_id]}\")\n",
    "    else:\n",
    "        print(\"No matching documents.\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
